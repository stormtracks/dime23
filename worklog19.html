<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_cds923z8fc97-0>li:before{content:"\0025cf  "}.lst-kix_cds923z8fc97-2>li:before{content:"\0025a0  "}.lst-kix_cds923z8fc97-1>li:before{content:"\0025cb  "}.lst-kix_xehe3iwuvouc-8>li:before{content:"\0025a0  "}.lst-kix_cds923z8fc97-4>li:before{content:"\0025cb  "}.lst-kix_xehe3iwuvouc-5>li:before{content:"\0025a0  "}.lst-kix_xehe3iwuvouc-7>li:before{content:"\0025cb  "}.lst-kix_cds923z8fc97-3>li:before{content:"\0025cf  "}.lst-kix_xehe3iwuvouc-6>li:before{content:"\0025cf  "}ul.lst-kix_xehe3iwuvouc-0{list-style-type:none}ul.lst-kix_xehe3iwuvouc-1{list-style-type:none}ul.lst-kix_xehe3iwuvouc-2{list-style-type:none}.lst-kix_xehe3iwuvouc-1>li:before{content:"\0025cb  "}.lst-kix_xehe3iwuvouc-3>li:before{content:"\0025cf  "}ul.lst-kix_xehe3iwuvouc-3{list-style-type:none}.lst-kix_xehe3iwuvouc-0>li:before{content:"\0025cf  "}.lst-kix_xehe3iwuvouc-4>li:before{content:"\0025cb  "}ul.lst-kix_xehe3iwuvouc-8{list-style-type:none}ul.lst-kix_xehe3iwuvouc-4{list-style-type:none}ul.lst-kix_xehe3iwuvouc-5{list-style-type:none}ul.lst-kix_xehe3iwuvouc-6{list-style-type:none}.lst-kix_xehe3iwuvouc-2>li:before{content:"\0025a0  "}ul.lst-kix_xehe3iwuvouc-7{list-style-type:none}ul.lst-kix_cds923z8fc97-8{list-style-type:none}ul.lst-kix_cds923z8fc97-7{list-style-type:none}ul.lst-kix_cds923z8fc97-6{list-style-type:none}ul.lst-kix_cds923z8fc97-5{list-style-type:none}ul.lst-kix_cds923z8fc97-4{list-style-type:none}ul.lst-kix_cds923z8fc97-3{list-style-type:none}ul.lst-kix_cds923z8fc97-2{list-style-type:none}ul.lst-kix_cds923z8fc97-1{list-style-type:none}ul.lst-kix_cds923z8fc97-0{list-style-type:none}.lst-kix_cds923z8fc97-8>li:before{content:"\0025a0  "}.lst-kix_cds923z8fc97-6>li:before{content:"\0025cf  "}.lst-kix_cds923z8fc97-5>li:before{content:"\0025a0  "}.lst-kix_cds923z8fc97-7>li:before{content:"\0025cb  "}ol{margin:0;padding:0}table td,table th{padding:0}.c7{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Arial";font-style:normal}.c0{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Verdana";font-style:normal}.c4{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Verdana";font-style:normal}.c12{-webkit-text-decoration-skip:none;color:#000000;text-decoration:underline;vertical-align:baseline;text-decoration-skip-ink:none;font-style:italic}.c1{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c5{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none}.c15{-webkit-text-decoration-skip:none;text-decoration:underline;text-decoration-skip-ink:none;font-style:italic}.c10{font-size:10pt;font-family:"Verdana";font-weight:700}.c3{font-size:14pt;font-family:"Verdana";font-weight:400}.c8{font-size:14pt;font-family:"Verdana";font-weight:700}.c16{font-size:10pt;font-family:"Verdana";font-weight:400}.c11{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{margin-left:36pt;padding-left:0pt}.c13{orphans:2;widows:2}.c14{padding:0;margin:0}.c6{color:inherit;text-decoration:inherit}.c2{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c11"><p class="c1"><span class="c0">Mon Dec 23, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Understanding the term, terminfo and pointer into postings and positions along with the document store.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sun Dec 22, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">First day working on fst. &nbsp;I read some of the blog post by burntsushi and got some of the fst code up and running with the examples.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sat Dec 21 (winter solstice, hb is going to the party in OR)</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So the year is ending on a good note, and my rust skills are in pretty good shape. &nbsp;I am finally starting to feel a bit productive, after starting to code in Rust on Scott&#39;s bday this year, so its been over 5 months now.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Today I got the code working to rebuild a json document based on the keys in the tantivy schema. &nbsp;It involved using a Map from serde-json, crossbeam channels for the first time, HashSets. &nbsp;I am pretty confident I can take a few weeks off from coding while I am back home in NM and get right back into some time in mid January once I am back home in OR.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wed Dec 18</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Up and running (again) with tantivy-cli. &nbsp;I got a new working example up and running, and pretty much understand how it works. &nbsp;Will outline the next steps in coming days. &nbsp;But for now I got the data coming from Hn and going into Redis, Sled, and Files which is where I wanted to get to. &nbsp;Now I am going to get up and running with easily getting the data into Tantivy.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Dec 17, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Moving on now to a new architecture with channels. &nbsp;So both IDs and Json Strings will go on channels moving forward.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sunday Dec 15, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Starting to get sled working with the hacker news json data. &nbsp;First cut at sled up and running and finished.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Dec 10, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">The day of flying to Florida I got the data into redis in the repo redsled. &nbsp;I just took the code from yesterday and added the method to write the data that was already in a vector out to redis.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Dec 09, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">The day before going to Fl I got the lifetimes example working noted in last Friday&#39;s entry. &nbsp;This is kind of HUGE and the next step in learning Rust. &nbsp;As I look over the Rust Book and what I still don&#39;t know, this was something I definitely needed to get down. &nbsp;So now I can take the rest of the day off :) &nbsp;See you in Florida. &nbsp;Its been a very productive time in Rust land here in Pittsburgh. &nbsp;I pretty much worked almost every single day and didn&#39;t take any days off while I was home. &nbsp;So until I get back to Oregon in mid January you can rest assured knowing you aren&#39;t a slacker when it comes to work :)</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday Dec 06, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I have been coding in Rust pretty much every day since arriving here in Pittsburgh and from the beginning on July 10. &nbsp;Today is the first time I ran into the borrow checker, lifetimes, and ownership, so this is pretty cool.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Here is the problem. &nbsp;I am reading data out of a file and passing that data into a Vector which then gets passed along somewhere else. &nbsp;The line iterator of the file owns the data and I want to be able to have a lifetime stating that the data lives on after the line iterator goes out of scope but the vector still can have a reference to the data.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">The fact that I am able to create a problem that uses these concepts is pretty cool. &nbsp;This may take a while to wrap my head around so stay tuned.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Dec 05</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Booked a ticket today to fly to ABQ on Dec 25 for $189. &nbsp;Believe it or not but this one line of code took me a couple of hours to figure out. &nbsp;Where keys is a vector, and I was trying to assign it to a variable via let x = but all it wanted was Vector on its own line calling the sort method. &nbsp;I was sorting a Vector of hash keys which are the hackernews ids for stories only.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">&nbsp;</span><span class="c4">&nbsp; &nbsp;let mut keys = get_hashmap_keys(&quot;hn-story-19&quot;.to_string()).unwrap();</span></p><p class="c1"><span class="c4">&nbsp; &nbsp; keys.sort();</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Dec 02</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So the null checks and everything else is running, now moving on to storing the data using both sled and probably redis too.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday Nov 30</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Lunch at Cafe 33 Taiwanese, yummy.</span></p><p class="c1"><span class="c0">Got null checks working in the repo hn-api-examples</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday Nov 29, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">hn-api-examples is up and running and I am parsing tens of thousands of hn json&#39;s with no errors. &nbsp;only thing left to do is handle the case where there is a null.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">make sure you understand this line of code:</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c16">Item::Comment(comment) =&gt; Some(&amp;comment.by.</span><span class="c10">as_ref().unwrap()</span><span class="c4">),</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Nov 18</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Up and running and the serde deserialization of a Hackernews json object is up and running.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday Nov 16</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Working on serde serial, deserial of hackernews in the context of spaceapi-rs. &nbsp;It is starting to work...</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Nov 14</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Note when I started coding in Rust we were at 1.36.0 and now today I installed 1.39.0</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">So the past couple of days in Pittsburgh have been trying and a bit brutal getting my async, tokio code working, but I am there with this rust-hackernews </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/stormasm/rust-hackernews/blob/master/hn00/examples/ex02.rs&amp;sa=D&amp;ust=1578016420658000">code</a></span><span class="c3">. &nbsp;It iterates over a set of hackernews favorite ids, gets the JSON body from </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://hacker-news.firebaseio.com/v0/item/8863.json&amp;sa=D&amp;ust=1578016420658000">here</a></span><span class="c3">, and writes the data to a redis hashmap. &nbsp;Pretty cool, and I believe it helped today to install the latest stable version of rust 1.39.0 which is the first version to support </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://blog.rust-lang.org/2019/11/07/Async-await-stable.html&amp;sa=D&amp;ust=1578016420658000">async-await</a></span><span class="c3">&nbsp;and here is the </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://news.ycombinator.com/item?id%3D21473259&amp;sa=D&amp;ust=1578016420658000">hackernews post</a></span><span class="c3">&nbsp;which got 1100 points, wow ! &nbsp;Initially I tried to tackle it using the hyper client code but then quickly realized that reqwest which was a much easier route to take.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday Nov 9</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I am in pretty good shape with the tantivy schema mod, and today I got a good handle on NamedFieldDocument which I learned is mainly used to help with document conversion to json.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Nov 05, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">In the morning before flying out to Pittsburgh. &nbsp;More work on tantivy, now looking at the Document and the schema crate in tantivy in relationship to the spaceapi-server concept but using this api to store tantivy documents, elastic-search documents, and possibly the concept of writing a tutorial on how to port data from elastic to tantivy using vector ?</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">also, with redis in mind fully understand how to use the RedisPool. &nbsp;I will basically get this for free as I unwind the spaceapi-server. &nbsp;For a second opinion on redis-pool take a look at sidekiq as well...</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday October 26, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">This week I started working on search in rust, more specifically, </span><span class="c8">tantivy and sonic</span><span class="c0">. &nbsp;I am not sure how I got here, but basically I wanted to store all of my hackernews favorite json files on redis or sled and then be able to search across them when it hit smack in the middle of the face that why not use a search engine library, and then I found tantivy and sonic. &nbsp;Life continues to twist and turn and its very strange how you discover the rocks and then eventually you turn them over.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday October 22, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Maria&#39;s birthday and Day 1 of tantivy.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday Sep 27</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Finally after many months of trying to understand Rust I am starting to code. &nbsp;The past 2 days have been working on reading the data back from Redis that maman writes to it... &nbsp;So I am finally am able to get at the data, and in doing so, am actually writing some Rust code.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Sep 26</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Some work on maman and getting serde to serialize and deserialize data from redis to a file etc...</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Sep 23</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Found out about jonhoo and his amazing Rust podcasts on Youtube. &nbsp;Making more progress on understanding Rust streams and futures. &nbsp;Today was a good day of understanding and getting more turned on to the concept of Pinning, which is well elucidated in one of John&#39;s videos.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thur Sep 19</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">See worklog trail on vector, http, hyper, async, await, future understanding...</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wed Sep 11</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Starting to understand events in the context of vector.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Sep 10</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sendlines is sending data into the elastic sink.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sendlines is up and running and I am successfully sending events from this rust example into the server; very cool and a significant event (NPI) in the evolution of my vector journey.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sunday Sep 01, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Found vector via </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://tokio.rs/blog/2019-08-tracing/&amp;sa=D&amp;ust=1578016420661000">this blog post</a></span><span class="c3">&nbsp;about tracing. &nbsp;I have been interested in both tokio and log tracing and so when I saw that vector was using both tokio and tracing I was happy. &nbsp;Vector is going to be my </span><span class="c8 c15">etcd</span><span class="c0">&nbsp;project for taking my Rust programming skills to the next level. &nbsp;At this moment it has 2177 stars which is enough to give the project some validity.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Other mission critical crates:</span></p><ul class="c14 lst-kix_xehe3iwuvouc-0 start"><li class="c1 c9"><span class="c0">serde</span></li><li class="c1 c9"><span class="c3">indexmap</span></li></ul><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Star Count over time</span></p><ul class="c14 lst-kix_cds923z8fc97-0 start"><li class="c1 c9"><span class="c0">2019 september = 2177</span></li></ul><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday Aug 23</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Very deep in the bowels of Rust. &nbsp;Today was typical across the board. &nbsp;Started out by looking at and understanding Codecs in Tokio followed by my first real foray into reading about macros followed by a glimpse into the internals of the rust compiler by just a peripheral reading of the rust compiler docs.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wed Aug 21</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Looking at the hyper and tower web frameworks in the context of tokio and futures.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Aug 13</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Starting to understand methods, versus free standing functions and traits.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Aug 12</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">First time really starting to code using sled as my basis for learning.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday Aug 10</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Starting to look into persistence engines such as sled.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Aug 8</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Cheryl and Michael&#39;s 8/8 party. &nbsp;More work on diesel in the context of Rocket. &nbsp;Working on a better understanding of lifetimes and macros in rust.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sunday Aug 4</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Postgresql up and running on my mac in prep for some diesel and crate.io work.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday July 31</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">More coding Tokio and Actix examples. &nbsp;This stuff is interesting.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday July 24</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">More coding in Rust with Tokio and a better understanding of async. &nbsp;Also how it compares to Golang, pros and cons.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday July 22</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Up and running with Rust and talking to redis. &nbsp;So I am just going to start doing more programming in Rust. &nbsp;Next up a better understanding of a </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/dbrgn/hn_api&amp;sa=D&amp;ust=1578016420663000">rust hacker news client</a></span><span class="c0">.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday July 17, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I have spent the past month working on the internals of flux and the month prior to that on influxdb. &nbsp;On May 10, 2019 I started working on the influxdb ecosystem in the context of a &quot;test&quot; system to work with the hashicorp ecosystem. &nbsp;I have spent enough time on the internals of flux that in the past 2 months while in the influxdb world that I learned two things. &nbsp;Two things in two months, pretty cool. &nbsp;And the 2 things are:</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">1) Rust</span></p><p class="c1"><span class="c3">2) </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://en.wikipedia.org/wiki/Hindley%25E2%2580%2593Milner_type_system&amp;sa=D&amp;ust=1578016420664000">Programming Language Theory of Types</a></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">So with that I will parallel track both above topics deeper and then circle back on Flux in both worlds. &nbsp;But the above two topics will not be a full time endeavor and so back into the influxdb world in tht context of equity data, but keeping abreast of the work going on in flux at the source code level. &nbsp;Specifically Rust and Affo&#39;s work on the redesign of </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/influxdata/flux/blob/master/docs/CompilationExecution.md&amp;sa=D&amp;ust=1578016420664000">Compilation and Execution</a></span><span class="c3">&nbsp;along with </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/influxdata/flux/pull/1332&amp;sa=D&amp;ust=1578016420664000">Pull Request 1332</a></span><span class="c3">.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday July 12, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">So I will remember Scott&#39;s birthday 2019 as the time when I started programming in Rust. &nbsp;My first programming in Rust was </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://blog.rust-lang.org/2019/07/04/Rust-1.36.0.html&amp;sa=D&amp;ust=1578016420664000">version 1.36.0</a></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">I will remember </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/stormasm/plum/commits/master?after%3D41fa28ab5eed239d6d4bcb0f6d6ad7360ca507bb%2B104&amp;sa=D&amp;ust=1578016420665000">my first golang project</a></span><span class="c0">&nbsp;in Ashland in November of 2014. &nbsp;This is the first November we spent in Ashland as November 2013 was the month we flew back home to NM from Oregon having just bought our house August 30, 2013.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday July 11, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c8">Day 1, Rust</span><span class="c3">&nbsp;motivated by </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/influxdata/flux/issues/1487&amp;sa=D&amp;ust=1578016420665000">this issue</a></span><span class="c3">&nbsp;on Fluxlang along with this </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://www.influxdata.com/blog/rust-can-be-difficult-to-learn-and-frustrating-but-its-also-the-most-exciting-thing-in-software-development-in-a-long-time/&amp;sa=D&amp;ust=1578016420665000">blog post</a></span><span class="c0">&nbsp;by Paul Dix at Influxdata.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">As I think back on my programming career I can only really think of learning 5 new programming languages in the 21st century. &nbsp;In order it was Javascript, Python, Ruby, Golang and now Rust. &nbsp;</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I learned Java in 1995 at Sfi and rode that wave through all of my career at Vitria into my time at Justice Systems when Brad turned me on to Javascript.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I learned Python prior to moving out to Caltech because Google&#39;s first implementation of their cloud infrastructure code used Python. &nbsp;At the time Guido was working at Google. &nbsp;</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I learned Ruby at the tail end of my time at Caltech as the final version of CRData was written in Ruby. &nbsp;I wrote the first version in Python. &nbsp;</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">In Buenos Aires I exclusively programmed in Javascript for my classroom image project and then upon my return to Placitas where I heavily got into Node.js for my project with </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://skift.com/2013/05/09/yahoo-to-shutter-milewise-flight-search-service-and-hire-team/&amp;sa=D&amp;ust=1578016420666000">Milewise</a></span><span class="c3">&nbsp;and their CEO </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/vpulim&amp;sa=D&amp;ust=1578016420666000">Vinay Pulim</a></span><span class="c3">.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I did all of my programming at Spinnakr in Ruby until the final year when I rewrote part of our code at Spinnakr in Golang.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I should mention that I briefly looked at Rust in the past but it might have only been for a day or two.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sunday July 7, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Big time progress on understanding </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/stormasm/flux-examples/tree/master/csv&amp;sa=D&amp;ust=1578016420666000">this repo</a></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">csv.from(csv: data) |&gt; sum(column: &quot;value&quot;)</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Now I have some more stuff to sink my teeth into and move forward from here. &nbsp;This could be the starting point for lots more independent testing of the different flux functions.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday July 4, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I got the gdayt code up and running, grabbing a set of filenames from a directory. &nbsp;I also have the date code working in go-examples/csv. &nbsp;So I am able to convert the ubnt.csv file into a file that can be written to influxdb. &nbsp;With that data in influxdb I will now circle back to understanding the flux scripts.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday July 1</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">First day back to work, and started working on remembering how to write data to influxdb and then starting to work on reading a CSV file and doing the time calculation correctly on the date.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday June 29</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">David Kleiman&#39;s birthday. &nbsp;I am back from Canada and we had a great trip. &nbsp;We drove home in one day from the Osoyoos border and had a nice Thai lunch in Yakima. &nbsp;Here are my plans moving forward, if you can stay focused and get this job done you will be in good shape. &nbsp;The last major task I undertook was the material-ui tutorial. &nbsp;And you got that job done. &nbsp;I will go back through this work log and see what I have done this year, but not right now. &nbsp;Stay tuned for an update on the progress to date at the half year point.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c15 c8">In a nutshell</span><span class="c0">&nbsp;here is what I need to do...</span></p><p class="c1"><span class="c0">1) Get daily closing data into InfluxDb</span></p><p class="c1"><span class="c0">2) Get fundamental data into InfluxDb. &nbsp;For now this will include just the spreadsheet items I have listed quarterly for Ubnt.</span></p><p class="c1"><span class="c0">3) Once the data is loaded up then calculate the 50 and 200 day moving averages using flux.</span></p><p class="c1"><span class="c0">4) Also calculate the trailing PE and forward PE.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday June 13</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Boyd&#39;s 78th birthday today. &nbsp;I got </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/stormasm/fluxspec&amp;sa=D&amp;ust=1578016420668000">fluxspec</a></span><span class="c3">&nbsp;up and running which is very cool. &nbsp;It just worked out of the box after a failed attempt with </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/leebyron/spec-md&amp;sa=D&amp;ust=1578016420668000">spec-md</a></span><span class="c3">. &nbsp;I also realized today why you should always create a branch with a public repo prior to commiting. &nbsp;It enables you to update the master branch from the public repo, and continue the branch you created untouched. &nbsp;Can&#39;t believe it took me this long to understand this concept. &nbsp;I realized it when my other pull request wasn&#39;t taken and I had to go out and get the latest code. &nbsp;When I did that and commited back I had to do a merge. &nbsp;Git continues to amaze me.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday June 11</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I have been spending the past number of days exclusively on the internals of flux and I am at a place where I can now move back into Influxdb and start writing some more sophisticated queries. &nbsp;Combined with the test data from the generate command and my flux knowledge I should begin to be able to create a cookbook or tutorial of flux queries in parallel with a deeper understanding of flux internals.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I am getting ready for our trip to Canada so it might be awhile before my next entry, but at least we have a plan when we get back from the adventure.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday May 31</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I am now building flux queries for the first time. &nbsp;Just got this going a couple of hours ago. &nbsp;It is Friday evening and we are making more progress on the Influx ecosystem. &nbsp;Yesterday I learned about schemas and the influxd generate command which gives me the ability to generate out some really cool test data.</span></p><p class="c1"><span class="c0">This product continues to impress me.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday May 23</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">For the first time got data from a text file into influxdb using the line protocol. &nbsp;I was also able to see the data in the chronograph ui. &nbsp;This is great news ! &nbsp;I have been messing around with this stuff for awhile and this is the first real progress.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Today I went to KP and had a visit with Sheila Jhansale who gave me a good report. &nbsp;I got an EKG done for the first time and she read it and said things looked good. &nbsp;Earlier in the day Hb and I walked in Minto Park and had lunch at the salem coop. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday May 17, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Found </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/markcheno/go-quote&amp;sa=D&amp;ust=1578016420669000">go-quote</a></span><span class="c0">&nbsp;which will be a big win for getting equity data into Influxdb.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday May 10, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Start looking at the </span><span class="c15 c8">Influxdb ecosystem</span><span class="c0">&nbsp;in the context of having it be a test bed for both hashicorp and docker.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday May 07, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Can not believe I have not posted anything for over a month. &nbsp;This just shows you where I have been at in my life and what has been going on... &nbsp;So to quickly summarize the whole time that past month has been spent coming more and more up to speed on the Hashicorp ecosystem. &nbsp;I have gone through everything at a high level and pretty much understand TVCN {Terraform, Vault, Consul, Nomad}. &nbsp;Now in the context of running a nomad job for redis I am revisiting the docker concepts and commands. &nbsp;Its great that I have my new computer back because now I can run docker on my Mac which is pretty darn handy.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday April 10</span></p><p class="c1"><span class="c0">Final day of work in Florida was completed with starting a deep dive into Terraform. &nbsp;The key point is that a separate process is running that Terraform talks to. &nbsp;Terraform calls into the particular Golang API for AWS, Digital Ocean or whatever other cloud its running on.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Terraform appears to be pretty cool. &nbsp;So now I have rounded off my initial understanding of the Hashicorp ecosystem and Terraform was the final shoe to drop in understanding. &nbsp;I have successfully tackled and completed phase I of the Hashicorp ecosystem. &nbsp;A lot more work needs to be done, but a good first step has been made.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday April 05</span></p><p class="c1"><span class="c0">More work on the details of Vault src code including starting to watch some stuff on Youtube and look at the Google Groups account for vault.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday April 01</span></p><p class="c1"><span class="c0">Vault Initialization Sequence is FINALLY nailed down</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday March 29</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Starting a deep dive into the Vault src code along with connecting up Vault to consul as one of the physical backends.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday March 27</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Day 1 of Hashicorp Vault</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday March 26, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Please see worklog18 on Friday Nov 2, 2018 for my first mention of Hashicorp again.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Day 1 looking at the hashicorp ecosystem including nomad after reading this </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://news.ycombinator.com/item?id%3D19467067&amp;sa=D&amp;ust=1578016420670000">blog post.</a></span><span class="c3">&nbsp; The code has to work out of the box and build and feel right. &nbsp;Traefik just seemed to be a bit broken and did NOT build out of the box. &nbsp;Nomad and the whole ecosystem seems to be the right chemistry and feels right and passes the smell test.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sunday March 24</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Spent some time looking at traefik.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday March 23</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Got my reverse-proxy working in go-examples.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday March 22</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Ended the week on a deep dive into etcd.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday March 18</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Worked all day on gostar3 and pretty much have it working.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday March 16</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Working on etcd, dgraph, tile38 on in the context of storage across more than one machine. &nbsp;dgraph accomplishes this via just using etcd raft, but I am not sure yet how this works. &nbsp;etcd uses boltdb for storing the key value pairs (on each node ?) &nbsp;I believe. &nbsp;So more research across the board on all of these topics. &nbsp;Could I use buntdb with raft and badger ?</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday March 8, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I now have the btree up and running and printing out the items in the node along with the number of children each has. &nbsp;From this information I can pretty much discern what the tree actually looks like. &nbsp;I don&#39;t think there is a need to take the time to display it in the browser. &nbsp;As long as I can understand the nodes and the children and levels we are good.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday March 5, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Continued deep dive into understanding B-Trees in depth.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday March 2, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Starting to look into B-Trees in the eventual context of Tile38.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Feb 26, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Arrive in Florida, Marsha picked us up at the airport and we went to Nino&#39;s for dinner.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Feb 21, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I am still working on just understanding how to build go repos with and WITHOUT go.mod. &nbsp;Today I banged my head against the wall for about an hour or two on NOT KNOWING that the </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">go get -t github.com/jpincas/tormenta</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">-t flag instructs get to also download the packages required to build the tests for the specified packages.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday Feb 20 [Eve&#39;s Birthday]</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So needless to say a lot has happened. &nbsp;I am back in Pittsburgh with my Dad, my Mom passed Sunday Feb 10, 10 days ago. &nbsp;This is my first entry since leaving OR. &nbsp;I am diverting now since I have my old macbook and its important to relearn again Golang. &nbsp;So that is what I will be doing in concert with some other things. &nbsp;Right now I am looking at http load testing and on the other side the http server.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday Feb 8</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I now understand a proxy, reverse and forward. &nbsp;Spending more time focusing specifically on Envoy and the details of that since it is at the core of Istio and more broadly used across the cloud landscape.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Feb 7, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">C++ sucks as bad as it always has. &nbsp;I tried building the Envoy Istio Proxy on my mac and it was a total joke. &nbsp;It took like 30 minutes to build and it still wasn&#39;t done. &nbsp;I eventually killed it off, that was the last time I will ever try and build a C++ binary like that again unless I am getting paid to build something like that. &nbsp;Pathetic how outdated the process of building something like that is compared to Golang which builds in like one minute for the same level of complexity. &nbsp;That is the difference between technology that is 30 years old versus 10 years old. &nbsp;No wonder no one ever writes C or C++ code.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday Feb 6, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Hb coming home from Redmond today.</span></p><p class="c1"><span class="c0">So, I love my job and here is why.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">All of this stuff came out of the need for something in my professional life. &nbsp;As I started using DO more and more, and I was diving deeper into Istio I noted on their website yesterday the link </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://preliminary.istio.io/docs/setup/kubernetes/platform-setup/docker-for-desktop/&amp;sa=D&amp;ust=1578016420674000">Docker for Desktop</a></span><span class="c0">.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Day 2 of Docker Desktop.</span></p><p class="c1"><span class="c0">Day 1 of Prometheus.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c4">docker run --name prometheus -d -p 127.0.0.1:9090:9090 prom/prometheus</span></p><p class="c1 c2"><span class="c4"></span></p><p class="c1"><span class="c0">Having the ability to run this above command is just GIGANTIC. &nbsp;It downloaded prom and I was up and running in literally less than 20 seconds. &nbsp;Docker Desktop is going to be a huge thing in my life going forward; this is clearly going to be one of my go to tools until the next big thing (like this) comes along.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Feb 5, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">I am up and running with Docker Desktop and Kubernetes on the Mac using the Docker dmg file which seems to work smoothly.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Feb 4, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">So I am fully up and running with Istio in terms of understanding at least how to run the helm command.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c12 c3">kubectl apply -f istio.yaml</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">The fact that this one command brings up everything in istio is very cool and actually quite amazing. &nbsp;Lots more work to do, but progress is clearly being made. &nbsp;I worked all day yesterday as well on this istio stuff, Hb went off to Redmond to be with the girls and I stayed home and had fun working.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Saturday Feb 2, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">I woke up this morning and istio and the sidecar proxy finally got figured out. &nbsp;The idea is simply this... &nbsp;Every application needs to call out to some type of API. &nbsp;Why not always have everyone call out to Envoy (the sidecar proxy) and then they can figure out, monitor, load balance and deal with who gets the request. &nbsp;Its like having a smart router sitting there figuring out how to route the traffic. &nbsp;Also, on the return trip the same thing. &nbsp;And the other huge win is that it is </span><span class="c8">not</span><span class="c0">&nbsp;EMBEDDED in the application. &nbsp;It doesn&#39;t have to be. &nbsp;In fact, the application doesn&#39;t know anything about the sidecar proxy, it just thinks its calling out to someone, and then getting a response back from someone.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Friday Feb 1, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">First time ever getting istio up and running fully on DO. &nbsp;My first attempt failed miserably as I was trying to bring it up on a 1 Gig machine. &nbsp;Then I went with the big guns of 4 Gigs and it worked beautifully.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Jan 31, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">So the effects of hearing about different stuff in my world comes together when you keep hearing about the same stuff. &nbsp;I came across this </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DRVZX4CwKhGE&amp;sa=D&amp;ust=1578016420675000">YouTube Post about Envoy</a></span><span class="c0">&nbsp;several weeks ago and then when it appeared again in istio I knew I needed to spend more time with it... &nbsp;Plus it is totally related to the Docker and Kubernetes work so it is a natural extension.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wed Jan 30, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Day 1 of hearing about and taking a look at istio which means sail in greek. &nbsp;So I am completed (for now) with Elasticsearch and writing out my HN Favorites to it. &nbsp;It all works, and Kibana works too.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Tuesday Jan 29</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Messing around with Ruby, Rvm, Jekyll on my new Macbook. &nbsp;It took me hours to get things figured out because of the stupid</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">ruby version </span><span class="c8">versus</span><span class="c3">&nbsp;ruby --version </span><span class="c8 c12">command</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">Any way, I don&#39;t believe I will ever make that mistake again with Ruby. &nbsp;And here are my </span><span class="c3 c5"><a class="c6" href="https://www.google.com/url?q=https://github.com/stormasm/link16&amp;sa=D&amp;ust=1578016420676000">Github Notes</a></span><span class="c0">&nbsp;about that in the future.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wed Jan 23</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c3">I am writing my HN Favorites out to a JSON file with </span><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://github.com/stormasm/hackernews-favorites&amp;sa=D&amp;ust=1578016420676000">hackernews-favorites</a></span><span class="c0">.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Monday Jan 21</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">See entry from yesterday. &nbsp;Today I figured out how the redishacker code works. &nbsp;This code reads json data out of hackernews and writes it to redis. &nbsp;The code is a bit tricky, but I am pretty sure I now understand most of it. &nbsp;I also got a source code version of kibana up and running, which is actually pretty impressive. &nbsp;It just worked out of the box which is a pretty good sign. </span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Sunday Jan 20, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Spent all day Sunday working on golang. &nbsp;I am sort of, kind of a bit back into golang. &nbsp;At least now I have a bit of a handle on go.mod as I struggled through getting my hackernews, redis, elasticsearch code back up and running. &nbsp;The key find was finding my code buried in another github repo. &nbsp;Boy, all of those github accounts actually come in handy and today was one of those big wins in finding the code. &nbsp;The 2nd big hurdle after finding the code was getting the modules stuff to work. &nbsp;I eventually ended up having to create a whole new repo with BulkStringRequest code in it; as forking olivere/elastic was not working as I could see the extra 2 files were not in ~/go/pkg... &nbsp;Any way, great news ! &nbsp;Now I have to figure out how the code actually works and then drive forward...</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Wednesday Jan 16</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Lots more work on Docker, especially in regard to getting nginx to run and all of the commands associated with it. &nbsp;I am documenting those commands now in my github repo which is actually a better spot than doing it in google docs. &nbsp;So the thing that drove me to continue on with Golang was realizing that getting a real live application deployed that works with Docker and Kubernetes probably makes sense. &nbsp;An application that I can scale out and demo to people that I know what the heck I am doing. &nbsp;So I am pulling out of the wood work my old code on redis, elasticsearch etc...</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Jan 10, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">A week has passed and a lot has happened, the main accomplishment was researching, communicating, and purchasing a new computer which I desperately needed. &nbsp;I bought an early 2015 Macbook Pro for $800 on Tuesday evening at 8PM at Starbucks. &nbsp;I purchased my first Macbook Pro on December 28, 2011. &nbsp;So basically more than seven years has passed since I purchased my last computer. &nbsp;I got it up and running yesterday; it only took me a few hours. &nbsp;It was good to basically go prior to Ken coming over to go for a walk around the park.</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">Thursday Jan 03, 2019</span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1"><span class="c0">First post of the new year and first post where I am starting this document with a blank slate. &nbsp;You will note that worklog18 encompassed all of my time since being fired by Buzzsumo back in the late summer of 2016, the last time I had a job where I was getting paid money. &nbsp;A lot of time has passed, and here we are. &nbsp;Started the day with getting nginx up and running on my DO, Digital Ocean droplet.</span></p><p class="c1 c2 c13"><span class="c7"></span></p><p class="c1 c13"><span class="c7">References</span></p><p class="c1 c13 c2"><span class="c7"></span></p><p class="c1"><span class="c5 c3"><a class="c6" href="https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vTHqs_BAQGFSiepgzF0pOVzfz0Fes8ftEP2ItKQarFXPAZQI5CLvwJIER20Og3nn83-BXmNGSR5cYPm/pub&amp;sa=D&amp;ust=1578016420678000">worklog18</a></span></p><p class="c1 c2"><span class="c0"></span></p><p class="c1 c13 c2"><span class="c7"></span></p></body></html>