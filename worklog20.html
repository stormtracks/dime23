<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_z0jagrrmg576-0>li:before{content:"\0025cf  "}.lst-kix_z0jagrrmg576-1>li:before{content:"\0025cb  "}.lst-kix_z0jagrrmg576-3>li:before{content:"\0025cf  "}.lst-kix_z0jagrrmg576-2>li:before{content:"\0025a0  "}.lst-kix_z0jagrrmg576-4>li:before{content:"\0025cb  "}ul.lst-kix_z0jagrrmg576-0{list-style-type:none}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ul.lst-kix_z0jagrrmg576-5{list-style-type:none}.lst-kix_z0jagrrmg576-7>li:before{content:"\0025cb  "}ul.lst-kix_z0jagrrmg576-6{list-style-type:none}.lst-kix_z0jagrrmg576-6>li:before{content:"\0025cf  "}ul.lst-kix_z0jagrrmg576-7{list-style-type:none}.lst-kix_z0jagrrmg576-8>li:before{content:"\0025a0  "}ul.lst-kix_z0jagrrmg576-8{list-style-type:none}ul.lst-kix_z0jagrrmg576-1{list-style-type:none}.lst-kix_z0jagrrmg576-5>li:before{content:"\0025a0  "}ul.lst-kix_z0jagrrmg576-2{list-style-type:none}ul.lst-kix_z0jagrrmg576-3{list-style-type:none}ul.lst-kix_z0jagrrmg576-4{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c6{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:10pt;font-family:"Verdana";font-style:normal}.c5{-webkit-text-decoration-skip:none;font-weight:700;text-decoration:underline;text-decoration-skip-ink:none;font-size:14pt;font-family:"Verdana";font-style:italic}.c1{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:14pt;font-family:"Verdana";font-style:normal}.c15{font-weight:400;text-decoration:none;font-size:26pt;font-family:"Arial";font-style:normal}.c16{padding-top:0pt;padding-bottom:3pt;line-height:1.15;page-break-after:avoid;text-align:left}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left;height:11pt}.c19{-webkit-text-decoration-skip:none;text-decoration:underline;text-decoration-skip-ink:none;font-style:italic}.c9{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none}.c2{padding-top:0pt;padding-bottom:0pt;line-height:1.15;text-align:left}.c20{font-weight:400;font-size:11pt;font-family:"Verdana"}.c11{font-size:10pt;font-family:"Verdana";font-weight:700}.c13{font-size:14pt;font-family:"Verdana";font-weight:700}.c21{font-size:10pt;font-family:"Verdana";font-weight:400}.c14{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c4{font-size:14pt;font-family:"Verdana";font-weight:400}.c18{font-weight:400;font-size:11pt;font-family:"Arial"}.c12{padding:0;margin:0}.c7{color:#000000;vertical-align:baseline}.c10{margin-left:36pt;padding-left:0pt}.c22{text-decoration:none;font-style:italic}.c3{color:inherit;text-decoration:inherit}.c8{orphans:2;widows:2}.c17{text-decoration:none;font-style:normal}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c14"><p class="c2"><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nushell/nushell/pulls?q%3Dis%253Apr%2Bauthor%253Astormasm%2Bis%253Aclosed&amp;sa=D&amp;source=editors&amp;ust=1614990639690000&amp;usg=AOvVaw2MLNJ5xor720GWp2N7fDDn">Pull Requests on Nushell</a></span></p><p class="c2"><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/document/d/e/2PACX-1vRbSl0L1ELww8d8ywDQo9LJXkp6nkNQilcxosK9TZNRQuiXm6GVG1UmXfMxvIvdWa2-ob0fEFjPIWaN/pub&amp;sa=D&amp;source=editors&amp;ust=1614990639691000&amp;usg=AOvVaw062lqQp0nZ5puWsocZUjz4">Link to this doc</a></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday March 05, 2021</span></p><p class="c2"><span class="c1">The last couple of days I have been working on scope; and today I nailed down how to startup / init nushell by sourcing an alias file located in my nuconfig repo.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Feb 25, 2021 [Sharon arrives tomorrow]</span></p><p class="c2"><span class="c4">I am loving </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/StylishThemes/GitHub-Dark&amp;sa=D&amp;source=editors&amp;ust=1614990639692000&amp;usg=AOvVaw0SDHbkn-gF7f_2JUqBzvFx">stylishthemes/github-dark</a></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Two more commits to nushell in the past week; so I am cranking along on making progress.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Feb 14, 2021</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Day one of Bevy, I got it up and running and the examples actually work out of the box, everyone I tried actually works which is very impressive. &nbsp;Don&#39;t worry; I will attempt to spend a small amount of time looking into this for now.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Day 1 of delta and tickrs too.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Feb 13, 2021</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Starting to do more work on understanding lex and parse_block which used to be called block and I renamed to parse_block which was the content of PR #3047.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Feb 12, 2021</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Got home from Ashland and Kfalls 2 days ago on Wednesday and on Thursday I did </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nushell/nushell/pull/3047&amp;sa=D&amp;source=editors&amp;ust=1614990639694000&amp;usg=AOvVaw3pcsK17UWMdXr51mgMqcbq">PR #3047</a></span><span class="c4">. &nbsp;This morning Jonathan had fixed all of the clippy warnings that got thrown post release of Rust 1.50. &nbsp;So I was able to merge main and Jonathan posted my PR.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Jan 31, 2021</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">After a week of work on #2972 I can move on for now. &nbsp;See the end of the issue and the discord conversation for more details. &nbsp;The bottom line is @lhkipp came up with a simple solution to fix the lexer; and it probably is the most elegant simple solution. &nbsp;But I don&#39;t feel I am up to the paygrade yet to go around fixing the lexer at this moment. &nbsp;Hopefully someone else will step up and do this work, or I will feel more confident to do this work at a later point in time.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Jan 29, 2021</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">I have been working all week on </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nushell/nushell/issues/2972&amp;sa=D&amp;source=editors&amp;ust=1614990639695000&amp;usg=AOvVaw2Ms4kTf2VoacxNfCjyyU5h">Issue 2972</a></span><span class="c1">. &nbsp;It is making me understand a lot more about the lexer and the parser then I ever thought I would have to know. &nbsp;&quot;The universe continues...&quot;</span></p><p class="c2"><span class="c4">This is a good project... &nbsp;Also this week on </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://news.ycombinator.com/item?id%3D25939122&amp;sa=D&amp;source=editors&amp;ust=1614990639696000&amp;usg=AOvVaw1JVjukOvE8ezHtU7SeokAG">Hacker News</a></span><span class="c1">&nbsp;I discoverd an article where it states how long and how much work it takes to acquire the knowledge to better understand a big complex piece of software.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Jan 22, 2021</span></p><p class="c2"><span class="c1">Yesterday I started working in earnest on nushell scripts. &nbsp;Darren has been working for awhile on this stuff and he has a nice repo with scripts in it; so I am using that as a model in which to move forward.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nushell/nushell/issues/2858&amp;sa=D&amp;source=editors&amp;ust=1614990639697000&amp;usg=AOvVaw34hBx7Uyju68kV9EfWI2j7">Jonathan&#39;s Big Todo List</a></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Jan 15</span></p><p class="c2"><span class="c1">So now that the nu-cli refactor is pretty much done; and I have taken a few days off on any hard core work; I am starting to think about what my next step in nushell is going to be...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">As an aside, this is the beauty of what you are doing. &nbsp;You get to decide and get excited about what you are going to work on and work on next. &nbsp;So it looks like my focus could possibly be on the state in nushell, the context, the environment, and how all of that stuff is tied together and works in the bigger picture. &nbsp;This is a logical next step for me, and will get me more into the programming aspects of things as opposed to the mechanics of moving a bunch of code around.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">This will also be related to the work on Jonathan&#39;s todo list of getting a new command going which....</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c19 c20 c7">maybe: would it be interesting to add the ability to query the context for </span></p><p class="c2"><span class="c19 c7 c20">what commands, variables, and aliases are in scope?</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Jan 11</span></p><p class="c2"><span class="c1">Huge day. &nbsp;Too much. &nbsp;It ended with Jonathan taking over because one of the tests on windows was failing and he was able to take the ball over the line. &nbsp;I was talking with Dad at 5pm after working all day since literally 7 this morning on getting the nu-core-commands crate up and running.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday January 10, 2021</span></p><p class="c2"><span class="c1">Will post when commit #5 lands, its now in the queue.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday January 4, 2021</span></p><p class="c2"><span class="c1">Cranking along on nushell with commit #4 landing...</span></p><p class="c2"><span class="c1">My first commit 2828 was on Dec 28, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c16 title" id="h.m7peoe9srg1b"><span class="c7 c15">2021</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So I end the year on this note about my first day of programming in Rust which I noted again on Monday Oct 26 was on Scott&#39;s birthday 2019.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday Dec 30, 2020</span></p><p class="c2"><span class="c1">One more commit lands, and one appears to be ready to land. &nbsp;I am on a roll and I am finally having fun programming in Rust after a very long while.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Dec 28, 2020</span></p><p class="c2"><span class="c1">I awoke this morning to a great piece of news...</span></p><p class="c2"><span class="c4">My </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nushell/nushell/pull/2828&amp;sa=D&amp;source=editors&amp;ust=1614990639701000&amp;usg=AOvVaw2fhGhoP3o9DLXwjd0JEsmy">first commit 2828 on Dec 28</a></span><span class="c4">&nbsp;</span><span class="c1">into nushell was accepted by Jonathan. &nbsp;We are up and running at work.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Dec 26, 2020</span></p><p class="c2"><span class="c1">Day 2 of Jonathan giving me the go ahead to refactor nu-cli. &nbsp;This is going to be a very interesting project, and challenging. &nbsp;Good luck.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Dec 22, 2020</span></p><p class="c2"><span class="c1">Starting to work on my own cli that calls into the nushell api parser et al. &nbsp;Finally starting to understand this stuff; as I am now writing code that calls into nushell and I am better able to understand what dependencies I need in Cargo.toml.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Dec 20, 2020</span></p><p class="c2"><span class="c1">Continue down Jonathan&#39;s update path. &nbsp;Lets get this stuff now, and get it documented and move on past this initial phase. &nbsp;Put it out there so others will understand too.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Dec 17</span></p><p class="c2"><span class="c1">More work on Jonathan&#39;s massive update as we move toward multiline scripts in nushell.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Dec 11</span></p><p class="c2"><span class="c1">Got bluemesa back up and running and added args to getfun. &nbsp;also starting to relook at parsing html via pandas.read_html which is used by yahoo_fin. &nbsp;Yesterday I tried parsing the yahoo finance quote page with rust but that was a complete failure so I am back to looking into parsing with pandas. &nbsp;It has 2 rock solid parsers including beautifulsoup which is also used to parse the edgar filings for xml / xbrl.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Dec 8</span></p><p class="c2"><span class="c4">As I was looking through github for hackernews repos I found </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/mjs2600/hn&amp;sa=D&amp;source=editors&amp;ust=1614990639703000&amp;usg=AOvVaw3X0m3wmx7pDDE0AC75GTgj">hn</a></span><span class="c4">&nbsp;which is a command line hn client. &nbsp;In there they use scraper which grabs the hn top posts. &nbsp;Day 1 of rust programs with the scraper technology.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Dec 7</span></p><p class="c2"><span class="c1">Starting to take a look at Jonathan&#39;s fork of nushell and the merging of nunu back into nushell. &nbsp;Last evening he told me where the fork was located. &nbsp;Also got hackernews favorites up and running with a fresh cut of all of the favorites through today.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Dec 4, 2020</span></p><p class="c2"><span class="c1">I am up to speed on nunu and jonathan is starting to merge it into nushell. &nbsp;rlox is in good shape now too. &nbsp;I want to switch gears now and re-focus my efforts on storing data in redis and sled and be up to speed on how to do it. &nbsp;So I am going to hold off on redis for awhile and just focus on sled. &nbsp;We will come back to redis later, but for now sled should get the job done, (I think)...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Nov 21, my 60th birthday</span></p><p class="c2"><span class="c1">Found another implementation of lox called rlox by radogost. &nbsp;This is very helpful for understanding how to write lang code in rust. &nbsp;Keep going; as this is very helpful.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Nov 20, 2020</span></p><p class="c2"><span class="c4">Last night I sent in a PR for rulox and Mario responded back within a few hours. &nbsp; I awoke this morning and already had an email from him. &nbsp;I am doing a deep dive into programming languages and a much better understanding of how they work on the inside. &nbsp;</span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=http://craftinginterpreters.com/contents.html&amp;sa=D&amp;source=editors&amp;ust=1614990639705000&amp;usg=AOvVaw2gVhkNt64BOpH-kEArB-8I">Crafting Interpreters</a></span><span class="c1">&nbsp;is a marvelous read and will be my seminal introduction (once again) to this aspect of computer science. &nbsp;Bill Macready would be happy to know I am here. &nbsp;My path in my work is all related and clearly this fork on the trail is related to my work the past number of months with nushell. &nbsp;We are at a point in the product where building a correct scripting language is required and so --- I need to understand this stuff. &nbsp;I love my job !</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Nov 10</span></p><p class="c2"><span class="c1">Back into Bluemesa specifically grabbing more data from Edgar. &nbsp;Using ubnt as my model data set.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday Nov 04</span></p><p class="c2"><span class="c1">Spent some more time on sled. &nbsp;I believe I am going to move back into bluemesa work to get a grip on how to push all 3 platforms forward: {bluemesa, nushell and sled}.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Nov 01</span></p><p class="c2"><span class="c1">The corvallisoddfellows.org domain name is transferred over to us from Wes in Hawaii, and the web site is up and running on gh-pages. &nbsp;Congrats, this is a big win for me and a testament to the ease of use of mdbook, which is rock solid.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Oct 31</span></p><p class="c2"><span class="c1">I think I now finally am starting to understand the whole type system and what it is all about for nushell. &nbsp;I think the light went on when I started thinking about html template engines in the context of zola as well as what is going on with serde json and how the output that you see whether it be json, a nushell table, or an html page is moving the data through the Value to what the end user sees. &nbsp;More on this later.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Oct 26</span></p><p class="c2"><span class="c1">So I went back the other day and found out that the first day I started programming in Rust was on Scott&#39;s birthday 2019. &nbsp;It has now been well over a year and I consider myself a bit more than a beginner, but at least I am still focused on the language, and becoming more knowledgable. &nbsp;Today I came back in once again to review Chapter 13 of the Rust Book on closures and iterators. &nbsp;They are all over the nushell code and so I need to fully understand the concepts. &nbsp;</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Oct 25</span></p><p class="c2"><span class="c1">I learned today that mdbook allows us to copy the complete theme directory over to your local mdbook repo where you are creating the book and then it will use those themes instead of the default ones in the binary. &nbsp;This means that I don&#39;t need to have my own custom copy of mdbook lying around but can simply embed the theme files I need for each particular mdbook repo that I create. &nbsp;So even though the odd fellow mdbook needs some changes, another mdbook may want other ones.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Oct 24</span></p><p class="c2"><span class="c1">Worked on a website for Bonnie and Oddfellows and had some minor breakthroughs. &nbsp;First I decided to use mdBook and was able to fix the sidebar so it stayed open by default and reduced the sidebar from 300px to 200px giving the user a lot more realestate on the right side. &nbsp;I like mdBook and will continue to use it more and more in other projects; plus it is written in Rust !</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Oct 22</span></p><p class="c2"><span class="c1">Going through the async/await book in reference to the futures trait and the stream trait in nushell and all of the calls associated with the futures crate. &nbsp;So basically we are doing a deep dive into everything behind futures in relation to nushell. &nbsp;This is actually the first time I have revisited this concept since working with Tokio awhile back and the first time looking at it since I started working on nushell back in July 2020. &nbsp;Its amazing how all of this stuff doesn&#39;t really stick around in my brain until I relearn it or re-remember it again.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Oct 18</span></p><p class="c2"><span class="c1">Finally realized that the tests in nu-cli need a binary to run and that is why main.rs gets sucked into the mix. &nbsp;It was not obvious till now that the nu! macro calls into the nu binary, upon thinking about it makes sense.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Oct 16</span></p><p class="c2"><span class="c1">nupro value/evaluate.rs</span></p><p class="c2"><span class="c1">nucli &nbsp; src/evaluate/mod.rs</span></p><p class="c2"><span class="c1">evaluator::evaluate_baseline_expr</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday Oct 14, 2020</span></p><p class="c2"><span class="c4">Spent all day on a bug in nushell where tests fail unless config.toml is empty or the skip welcome message is not set. &nbsp;not sure today was productive, but I am very happy as all my tests are passing... &nbsp;and I know why !! &nbsp;it had to do with </span><span class="c13 c7 c17">config.toml</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Oct 12, 2020</span></p><p class="c2"><span class="c1">Deep dive into the underlying commands and how free data gets parse in nushell including all of the core commands {parse, each, split, etc...}</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Oct 11, 2020</span></p><p class="c2"><span class="c1">Working on Value as well as regex associated with the nushell parse command. </span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Oct 3, 2020</span></p><p class="c2"><span class="c1">More work on exactly what a value is in Rust.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Oct 1, 2020</span></p><p class="c2"><span class="c1">Massive dive into true understanding of Literals, Expressions, and Values in both the context of nushell and Rust.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Sep 28</span></p><p class="c2"><span class="c1">Luke&#39;s birthday. &nbsp;flexi_logger is up and running inside nushell and logging all log messages either to a file or to the console. &nbsp;It works exactly like I wanted it to. &nbsp;Once I figured out flexi_logger this afternoon I had the whole main.rs nushell file pared down and back up and running with the new logging code in about 1 hour. &nbsp;Very cool ! &nbsp;Rust logging is working the way it should, and nushell is very well designed from a logging perspective... &nbsp;Once you understand this stuff it is really trivial and easy. &nbsp;Today was an example of how things fall into place. &nbsp;However, it took me a number of days to finally get here and come up with this simple solution.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Sep 25</span></p><p class="c2"><span class="c1">A week has passed. &nbsp;We are now deep into how Rust logging works. &nbsp;I want to integrate a new logging solution into the Nushell code for personal use. &nbsp;For now, the focus is as simple as; writing the log data out to file instead of stdout. &nbsp;(I think)...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Sep 18</span></p><p class="c2"><span class="c1">Moving quickly, I now understand that nu-table is the crate that draws the table data. &nbsp;I now need to work out exactly how this data gets fed to draw_table and when a table is drawn and when one is not... &nbsp;As always, more work to do. &nbsp;But I have gotten past the parser for now, and moved on to the other side of the equation. &nbsp;There is a lot more to understand with nushell; but I think we are making progress. &nbsp;Stay tuned here for more details :)</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wed Sep 16</span></p><p class="c2"><span class="c4">still smoky during the day but by evening it cleared and we went for a big walk in WL. &nbsp;still working on lite_parse, with a major deep dive into all aspects of how </span><span class="c5">lite_parse</span><span class="c1">&nbsp;in nushell works.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Sep 15</span></p><p class="c2"><span class="c1">Day-1 working on the nushell-notes Day 1 of mdbook. &nbsp;This is the start of my adventure getting this book up and running.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Sep 14</span></p><p class="c2"><span class="c1">this evening we went for a walk at night and it was the first time since last Monday that the skies were clear. &nbsp;Its been a crappy week as far as smoke is concerned. &nbsp;I am way deep into understanding the crates {nu-parser, nu-source}... &nbsp;I assume this should go on at least another week or two, or until I fully understand these 2 crates plus {nu-protocol}.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Sep 07</span></p><p class="c2"><span class="c1">jturner and I had our first talk about nushell. &nbsp;He is a cool guy. &nbsp;This morning I read the RFC on dataframes and made some comments on discord, and soon we were discussing the spec he wrote up. &nbsp;I am going to spend more time looking at streaming based on our talk today.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Sep 04</span></p><p class="c2"><span class="c4">Listened to most of this </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://changelog.com/podcast/363&amp;sa=D&amp;source=editors&amp;ust=1614990639712000&amp;usg=AOvVaw0Sv_Q5ZJ3-TR1ACmAvwMrC">podcast</a></span><span class="c4">&nbsp;which was shot in September 2019 of the 3 founders of nushell. &nbsp;Today was day 1 of looking into the plugins. &nbsp;It was motivated by this </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://discordapp.com/channels/601130461678272522/729071784321876040/751280252134752328&amp;sa=D&amp;source=editors&amp;ust=1614990639713000&amp;usg=AOvVaw2mwr1VAnIOsqeGUAcYNxed">chat</a></span><span class="c1">&nbsp;I had with jturner on 9/3 which was yesterday in the documentation thread. &nbsp;I was trying to understand why sys wasn&#39;t working and it was because I was copying the nu binary over to another directory that did not have the plugins in there. &nbsp;Once I fired up the /target/debug nu version everything worked and I pulled in all of the default plugins. &nbsp;Then today I got the sqlite plugin working and started to work on understanding how the underlying plugin architecture using jsonrpc works.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday Sep 02</span></p><p class="c2"><span class="c4">Massive dive into </span><span class="c4">nushell </span><span class="c4">! &nbsp;Its all I have been doing since the last entry on August 24. &nbsp;Yesterday I discovered the github repo </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/nushell/demo&amp;sa=D&amp;source=editors&amp;ust=1614990639713000&amp;usg=AOvVaw1J2n80RMYeF9ugcsEKKol5">nushell/demo</a></span><span class="c4">&nbsp;which was great to find because for the past week I had been seeing the method </span><span class="c5">parse_and_eval </span><span class="c4">inside nu_cli but it was not referenced anywhere in the whole nushell repo. &nbsp;Whenever I did a rg on it, nothing came up that was using it. &nbsp;And then yesterday I discovered the wasm demo repo by reading over the old nushell blog posts. &nbsp;Wasm was introduced in the </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://www.nushell.sh/blog/2020/07/21/nushell_0_17_0.html&amp;sa=D&amp;source=editors&amp;ust=1614990639714000&amp;usg=AOvVaw3rR7vRMEFwklDCJyIGNA93">17.0 version blogpost</a></span><span class="c4">. &nbsp;So tonight, I got run_nu up and running with a simple example which is currently in my nuwasm repo which will probably eventually be moved somewhere else but for now thats its landing spot.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday August 24</span></p><p class="c2"><span class="c1">Yesterday I started into the nushell discord which is giving me a big insight as to how nushell works. &nbsp;Today I downloaded the first version just to get a glimpse of the original ideas behind the program. &nbsp;In concert with this info, I was able to convert the ui xbrl 10q file into a table and then back into json and the whole thing worked. &nbsp;This is amazing ! &nbsp;Also spent some time looking at toml to get a handle on their very simple, very intuitive format. </span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday August 20</span></p><p class="c2"><span class="c1">Deep in the throes of Nushell, and making HUGE progress on understanding the inner workings of it. &nbsp;Hopefully this will be relevant going forward. &nbsp;Stay tuned.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday August 17</span></p><p class="c2"><span class="c1">Pedro&#39;s bday. &nbsp;Today I launched in a big way back into nushell. &nbsp;So I will attempt to work on 2 projects at the same time which could be a bit tricky. &nbsp;Stay tuned.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday August 14</span></p><p class="c2"><span class="c1">Contextref in soup-xbrl is ready to be written out to a dictionary. &nbsp;Then I will do the other tags. &nbsp;Idea is to have a complete dictionary representation of the xbrl 10q / 10k file and then write that out to whatever including json, csv, redis, sqlite etc... &nbsp;We are making massive progress on this front.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday August 11</span></p><p class="c2"><span class="c1">Starting to break out a new class called ContextRef. &nbsp;Will document here more what it does.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday August 5</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Decided today to go away next Monday for a week or so. &nbsp;I learned today that our shed will not be delivered for several weeks so next Monday is a good day to go away. &nbsp;I now fully understand data_processing and passing in the context_ids.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So here is whats on tap when I get back from my trip. &nbsp;I may update this further prior to departure but here goes for now.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So I am just at the point where I am understanding how to grab all of the correct context and associated context_ids that I need to get certains data points and data sets. &nbsp;I will work out exactly what data points in the 10Q&#39;s are associated with what particular contexts but this for now is where all of the work will be going upon return. &nbsp;Capturing all of the data is possibly a function of getting the correct 3 month intervals associated contexts. &nbsp;That is step 1. &nbsp;Getting all of the associated quarterly data.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Once this is done then you can move on to getting the annual data. &nbsp;And lastly the 2 quarters / 6 months and 3 quarters / 9 months worth of data.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">But for now just getting all of the 3 month data is not obvious as the current 2 context id&#39;s that I am pulling does appear to get all of the data and I also don&#39;t know out of all of the data points on the 10q what data points are 3 month data points and what data points are other contextrefs.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday August 3</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">More parsing of the edgar xbrl docs. &nbsp;I now have the name of the tag along with the value and starting to work on the child tags and grabbing the context data.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday July 31</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Day 2 of working on xbrl. &nbsp;I now understand the work I need to do to move forward. &nbsp;Be able to get the date and the context id&#39;s automagically from the file name and a particular xml element.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday July 30</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c5 c7">Day One of Parsing XBRL Files</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Lots of work on parsing XBRL and winnowing down the parsing for the quarterly UI files. &nbsp;We are up and running and getting a small subset of GAAP and cleaning up the xbrl parser file with just the bare essentials.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday July 28</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Got all of the ubnt data going back to the beginning of time from their website and archived it in numerous locations. &nbsp;Now I can dive in further and make sure I have all of the data. &nbsp;This is a great model to better understand cash flow and the other interesting notes of a much bigger picture. &nbsp;Also calculated the avg share price of UI&#39;s purchases since the beginning of time. &nbsp;They spent just over 2B to purchase almost 28M shares at an average price of $75. &nbsp;I used the cash flow statement to see how much stock they bought back each year starting with year 2012.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday July 27</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Major, massive push to a better understanding of the cashflow statement. &nbsp;In fact I got so excited, that I put together a google sheet for the first time for </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://docs.google.com/spreadsheets/d/e/2PACX-1vQ53tfs7Nn8mvIbO2s-gRY5nhVqKMr4rtJf89-fErN4AI4zUL3X2crXPHykr7o7kOhX449QjRsJg6Hr/pubhtml?urp%3Dgmail_link&amp;sa=D&amp;source=editors&amp;ust=1614990639720000&amp;usg=AOvVaw2x5jY8oQUYcVYCSijcHwko">ubnt&#39;s 2020 cash flow</a></span><span class="c1">&nbsp;statements. &nbsp;I copied over all of the numbers from the 10Q&#39;s and reconciled that the numbers were exactly correct.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">I have been wanting to do this for years, and get a better hold and understanding of how all of these numbers flow. &nbsp;I think my conversation yesterday with Lukas got me to do this today.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">The main thing I wanted to see was how all of the numbers literally add up, and now I can prove to myself exactly what the heck is going on with the cash flow statement.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday July 26</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">First contact with Lukas at Causal after reading their blog post </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://www.causal.app/blog/whats-a-financial-statement&amp;sa=D&amp;source=editors&amp;ust=1614990639722000&amp;usg=AOvVaw31Qr-X2FId8Cqpuwe_dQPO">Financial Statements: A Beginner&#39;s Guide</a></span><span class="c1">.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday July 23</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Starting to get a handle on nushell. &nbsp;Python regex up and running removing {M,B,%,$} from fun and mcap numbers so that nushell sorts correctly. &nbsp;It doesn&#39;t like to sort with other characters in the numbers. &nbsp;Yesterday I got a handle on how to search and go back in time on discord. &nbsp;Now I can go back to the beginning of the nushell history and get a better handle on how things work.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday July 21</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So I have been pretty busy working on some different things. &nbsp;First of all bluemesa is in a good spot. &nbsp;The next thing I need to do is start sorting all of the data inside the CSV. &nbsp;I got the mcap fundamental data from Fidelity now pretty much up and running.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">What I did was download all of the stocks whose market cap is greater than &gt; 1B and broken it up into categories where the largest one is &gt; 90B and on down. &nbsp;Then I got all of those symbols sorted out and accompanying names of the companies in the redis key symbol hash. &nbsp;Then from there I was able to create a CSV file from the Yahoo Fun data. &nbsp;And then I hit the road block which sent me down my 2nd rabbit hole.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Nushell only sorts integer columns but not floats. &nbsp;So I dove into nushell to see what was up and came across an issue with running</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">cargo run src/main.rs</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">I found a solution but not sure of what the cause of the problem was. &nbsp;In the meantime, I went back to take a 2nd look at alacritty to make sure I understand what that is. &nbsp;Its a terminal emulator that brings up a new window. &nbsp;Clearly, nothing to do with shells but it took me a bit of time to remember what a terminal emulator is...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday July 12, 2020</span></p><p class="c2"><span class="c1">Day one of nushell. &nbsp;this may not be the exact first day, but it is close enough to this day, to revise history and note that my first day of nushell was exactly one year after my first mention in my blog of rust, or more exactly day 1 of rust. &nbsp;so nushell came one year to the day of rust.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday July 9</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">python-xbrl-test up and running. &nbsp;starting to look at xbrl and the mapping between </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=http://www.xbrlsite.com/2015/fro/us-gaap/html/ReportFrames/COMID-BSU-CF1-ISM-IEMIA-OILY/mapping-definition.html&amp;sa=D&amp;source=editors&amp;ust=1614990639725000&amp;usg=AOvVaw2cPV7FQ4b1Smzrd-XeruyS">fundamental accounting concepts and gaap</a></span><span class="c1">.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday July 3, 2020</span></p><p class="c2"><span class="c1">Now that we have symbols in place for the Russell 3000 in the form of IWV we can now venture off to start to use these symbols to get fundamental data via Project Edgar. &nbsp;Step 1 was to have the ability to download the Edgar files and then parse the XBRL. &nbsp;That is where the beautifulsoup comes in which is what I am currently working on.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday July 1</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Got iwv symbols integrated into the bluemesa system. &nbsp;so now we have a lot more symbol data to play with...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday June 30</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">In search of symbols and I found them from </span><span class="c4 c9"><a class="c3" href="https://www.google.com/url?q=https://www.ishares.com/us/products/239714/ishares-russell-3000-etf&amp;sa=D&amp;source=editors&amp;ust=1614990639727000&amp;usg=AOvVaw3NNqKLujCqY3JYhjmd_sEz">ishares IWV</a></span><span class="c1">. &nbsp;This has just under 3k symbols which is about 90% of the US equity markets so this will be enough symbols to populate my entire symbol db and then I will add any additional symbols as needed but this bootstraps my symbol library / db. &nbsp;In the afternoon I learned more about spreadsheets and how to reference one cell in another cell. &nbsp;I have been trying to understand how to do this for a couple of sessions and today I figured it out, very cool. &nbsp;Spreadsheets are really powerful and it has been just the past few years that I have learned better how to use them. &nbsp;Yesterday I spoke to Eli Scavron for awhile, its been many months since we last spoke.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday June 19</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">We learned today about the Juneteenth holiday for the first time. &nbsp;Google did a doodle on it. &nbsp;I also figured out how Python modules and packages work. &nbsp;The key breakthrough was adding the /j/tmp32/bluemesa/py to the end of the PYTHONPATH. &nbsp;I am really truly loving Python. &nbsp;When I was programming in the language back at Caltech I did not have the background or knowledge of really understanding Javascript, Ruby, Go and Rust and then coming back at Python for a 2nd time gave me a lot more &quot;dry powder&quot; to understand it. &nbsp;I am already a very happy and productive Python programmer and am cranking out code fairly fast for bluemesa.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday June 15</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c5">This was my first commit to bluemesa</span><span class="c1">. &nbsp;We are starting to get up and running with whole new repo about &quot;equity analysis&quot;. &nbsp;Some of the tools will be in Python and some of the tools will also be written in Rust. &nbsp;We are off to a good start.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday June 12</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">I can not believe how easy it is to code in Python. &nbsp;I am blown away by the elegance and simplicity of the language. &nbsp;Compared to Rust Python is a breeze. &nbsp;And its also way simpler than Javascript tambien.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wed June 10</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Up and running with Alacritty. &nbsp;Eventually this and the terminal work could be possibly integrated together. &nbsp;A better understanding of screen buffers, terminal emulators and the knowledge surrounding this subject.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday June 8</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Starting to look at ben ashford&#39;s redis client that uses a very nice design of the RESP protocol.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday June 7</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Starting to look at Rust tui&#39;s (terminal UIs).</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday June 6, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Checked out the rust redox-os.org OS. &nbsp;Also going to spend lots more time building and designing terminal UIs in rust and use the python </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/willmcgugan/rich&amp;sa=D&amp;source=editors&amp;ust=1614990639731000&amp;usg=AOvVaw3J7Wq4wZKKcap_zFR8BvqL">rich</a></span><span class="c1">&nbsp;version as one of my models.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday June 05, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Up and running with Python, Go, and Rust grpc server and client along with a better understanding of protocol buffers. Earlier in the week I worked on Rust serde and a better understanding of Rust traits. &nbsp;Lots more work needs to be done on getting more up to speed on the advanced concepts in Rust.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday May 22</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Watched the </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DHqi_Bw_0y8Q&amp;sa=D&amp;source=editors&amp;ust=1614990639732000&amp;usg=AOvVaw2_m9i4t8pR-SXoVFWMhYS2">Youtube video</a></span><span class="c1">&nbsp;by Wes McKinney author of pandas and arrow</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday May 21</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Diana Martin died today as I turned 59.5. &nbsp;Also, starting to take a look at Apache Arrow and Parquet which is mentioned by Paul Dix in a </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://www.influxdata.com/blog/apache-arrow-parquet-flight-and-their-ecosystem-are-a-game-changer-for-olap/&amp;sa=D&amp;source=editors&amp;ust=1614990639733000&amp;usg=AOvVaw0YvtWIXa213AWo2fSMaUaC">blog post</a></span><span class="c1">.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday May 20</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Back into Rust with a look at protobuf and grpc in the context of Hyperium and Lucio Franco&#39;s tonic. &nbsp;I spent all day kind of slashing around looking for the &quot;right&quot; first package solution that I could sink my teeth into. &nbsp;Of course, I need grpc for my sp500 project, but in and of itself it looks to be a very interesting area to focus on for awhile. &nbsp;Especially in concert with using Python. &nbsp;The combination of these two languages may turn out to be a match made in heaven !:)</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday May 13</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Wrote my first &quot;real&quot; Python program </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/stormasm/python-examples/tree/master/json&amp;sa=D&amp;source=editors&amp;ust=1614990639735000&amp;usg=AOvVaw150fBlBGgMvZrrIaag7BGT">here</a></span><span class="c1">. &nbsp;It took in the sp500 list of quotes for each industry group and created a json file with just the industry group symbol and the set of symbols in that group. &nbsp;I like Python alot, and I am impressed by how simple of a language it is... &nbsp;Coming back to it really for the first time since programming in it at Caltech for the first version of crdata. &nbsp;The 2nd version was re-written in Ruby.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday May 05</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Ta is completely up and running, it just all works, and I fully understand now how to use the api. &nbsp;</span><span class="c4 c19">Getting back</span><span class="c1">&nbsp;into python was a brilliant and lucky move on my part especially in the area of finance. &nbsp;And the whole motivation came initially from my work in influxdb and flux and realizing that instead of doing my processing in flux which is not the right way to go, was do possibly explore Python. &nbsp;Turns out to be a lucky and good choice. &nbsp;Influxdb and Paul Dix was also the motivator for me getting into Rust initially when I found out and saw that the Flux parser was written in Rust mainly for compatibility with wasm. &nbsp;Its a very cool world on the technology front.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday May 04</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Reading ui.csv files into ta and running the algorithms on strategies that just take in close as an input parameter.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday May 01, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">As I started getting into my first Python package ta I realized I needed to review Python modules, packages, and classes.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday 30</span></p><p class="c2"><span class="c4">Begin spending more time looking at </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/bukosabino/ta&amp;sa=D&amp;source=editors&amp;ust=1614990639737000&amp;usg=AOvVaw183jrB9_VkKN-J8mUP4Irj">ta</a></span><span class="c1">.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday 29</span></p><p class="c2"><span class="c1">Starting to spend more time looking at pandas and matplotlib.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday April 27</span></p><p class="c2"><span class="c1">Deep dive into numpy, wow ! &nbsp;And to think I was using this at caltech in the good old days and I am back here again literally more than 10 years later like no time has passed. all of this is (of course) in the context of looking at flux versus other ways to process and compute on the time series equity data. &nbsp;So using flux makes no sense for computation, flux only needs to be used for getting data in and getting data out of influx and literally nothing else. &nbsp;numpy and pandas makes life so easy, and I am just starting to use it.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday April 25</span></p><p class="c2"><span class="c1">Revisited python virtual envs and started using pipx which seems to do the trick for me.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday April 23, 2020</span></p><p class="c2"><span class="c1">E&#39;s 26th Bday. &nbsp;Summary for the week so far... &nbsp;I think I now understand wasmtime and what a wasm standalone runtime is. &nbsp;Also, ran a bunch of python tests on different technical analysis software written in rust.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday April 20, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Day 1 of Python. &nbsp;Day 1 of Catalina Version 10.15.4. &nbsp;What a mess, they changed the shell to zsh and made the root directory read only which means you have to run a command everytime you reboot which is a pretty big hassle in my view. &nbsp;I got Python up and running and some nice tests running which talks to Influxdb. &nbsp;So the Influxdb Python client is starting to get up and running and it appears to be pretty nice. &nbsp;The idea is to do most of the processing in a language like Rust or Python and do minimal processing in Flux for now. &nbsp;I learned yesterday that all of the flux code has to be in one file because user packages are not yet working.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday April 19, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">This was a big week of Flux and a better understanding of the language. &nbsp;I believe I am back to where I was last July 2019.</span></p><p class="c2"><span class="c1">So here is my list of stuff going forward in no particular order.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">The thesis of this list is Rust programming...</span></p><p class="c0"><span class="c1"></span></p><ul class="c12 lst-kix_z0jagrrmg576-0 start"><li class="c2 c10 li-bullet-0"><span class="c1">get back into tantivy with a focus on the client</span></li><li class="c2 c10 li-bullet-0"><span class="c1">work on rust client for influxdb 2.0</span></li><li class="c2 c10 li-bullet-0"><span class="c1">work on RSI (relative strength index)</span></li><li class="c2 c10 li-bullet-0"><span class="c1">both in rust and go</span></li><li class="c2 c10 li-bullet-0"><span class="c1">eventually port the go version into influx</span></li><li class="c2 c10 li-bullet-0"><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/greyblake/ta-rs&amp;sa=D&amp;source=editors&amp;ust=1614990639741000&amp;usg=AOvVaw1ngYCTGxsBL2J2rbg5eQZK">https://github.com/greyblake/ta-rs</a></span></li><li class="c2 c10 li-bullet-0"><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/markcheno/go-talib&amp;sa=D&amp;source=editors&amp;ust=1614990639741000&amp;usg=AOvVaw35SwOvRcHx9zyDo-s0UQ_g">https://github.com/markcheno/go-talib</a></span></li><li class="c2 c10 li-bullet-0"><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/markcheno/go-quote&amp;sa=D&amp;source=editors&amp;ust=1614990639742000&amp;usg=AOvVaw26Np0Hlvqo6zWpKWoTWoWa">https://github.com/markcheno/go-quote</a></span></li></ul><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday April 13</span></p><p class="c2"><span class="c4">Diving deeper into Influx. &nbsp;Yesterday I had a conversation with Paul Dix about the piece he wrote recently about a tutorial he wrote on new upcoming features in Flux. &nbsp;I am spending more time once again understanding Flux and the pieces that surround reading data out of influxdb and into the Flux engine. &nbsp;All of that stuff comes from </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/influxdata/influxdb/blob/master/query/stdlib/influxdata/influxdb/from.go&amp;sa=D&amp;source=editors&amp;ust=1614990639742000&amp;usg=AOvVaw239GvGRoEe-ylarahx9SGt">from</a></span><span class="c1">. &nbsp;</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Also huge breakthrough in understanding of the fact that I can </span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">go run &nbsp; cmd/influxd/main.go</span></p><p class="c2"><span class="c1">go build cmd/influxd/main.go</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">All day I was trying to rip out src code and understand how UI is related so that I can remove stuff or pare it down and in the end this is all I had to do... &nbsp;You do get a 500 Internal Server error but how all of this stuff is tied to the go build process is for future research, for now the fact that I can quickly </span></p><p class="c2"><span class="c4">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; </span><span class="c5 c7">build an influxd binary </span></p><p class="c2"><span class="c4">without going through the whole UI yarn cluster-f--k of building the complete React UI system is a HUGE win. </span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday April 06</span></p><p class="c2"><span class="c1">More progress... &nbsp;I got the whole flux script up and running today. &nbsp;I am actually able to see results in both the influx UI as well as running flux script via &#39;influx query @ex00.txt&#39;. &nbsp;I am impressed, this stuff actually works really well and I accidentally discovered the simple solution to the 200 day moving average and it matches up with the result on yahoo; very cool. &nbsp;Its just the mean calculation using the past 200 days. &nbsp;What a life !</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday April 03</span></p><p class="c2"><span class="c4">I am happy to say after several weeks of hard work that I am finally reading a yahoo historical equity csv file and writing out the data in </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://v2.docs.influxdata.com/v2.0/reference/syntax/line-protocol/&amp;sa=D&amp;source=editors&amp;ust=1614990639744000&amp;usg=AOvVaw0Caf5nW8WlGpYlJb85F8Qk">influxdb line protocol format</a></span><span class="c4">. &nbsp;Here is the </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/stormrust/influx-point-lineprotocol&amp;sa=D&amp;source=editors&amp;ust=1614990639745000&amp;usg=AOvVaw1CQQvciiVqQ16TmkM8zEU8">influx-point-lineprotocol</a></span><span class="c1">&nbsp;repo. &nbsp;The hard part the past 2 weeks was a better understanding of rust structs along with the ownership, borrowing and especially the reference concept in Chapter 4 of the Rust Book.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wednesday April 01</span></p><p class="c2"><span class="c1">Reading the ownership chapter in the Rust book, Chapter 4 and this time I believe its starting to sink in better. &nbsp;Especially now since I really needed to understand structs and how they work in regard to the concept of a Reference in Rust. &nbsp;I think I am finally starting to get the point. &nbsp;Boy does this stuff take a while to get.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday March 30</span></p><p class="c2"><span class="c1">Big time deep dive into structs in Rust including borrowing and ownership. &nbsp;I need to understand this crap.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday March 24</span></p><p class="c2"><span class="c1">First day of working getting Point up and running inside the src tree with a real crate and real structs with methods all being called from example. &nbsp;This is my first time ever really starting to understand this concept in Rust. &nbsp;Its amazing how long I have been working in this language to finally get to this place. &nbsp;This stuff takes a lot of time.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday March 20, 2020</span></p><p class="c2"><span class="c1">So I spent the day looking at the Point implementation in Influxdb along with the rust client for 1.7x, along with the line-protcol for 1.7x. &nbsp;I am going to do an array of structs with {measurement, time, fieldset and tagset}</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday March 17, 2020</span></p><p class="c2"><span class="c1">First real day of coding back up and running with Rust. &nbsp;Read equity csv files and writing the data to an InfluxDb file format.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday March 6</span></p><p class="c2"><span class="c1">Final check in prior to heading down to Ashland. &nbsp;Lots of work on Influxdb since last update. &nbsp;Tons more to do... &nbsp;Not sure this is the right path, but I am heading down it...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Feb 28</span></p><p class="c2"><span class="c1">Start working again on understanding flux.</span></p><p class="c0"><span class="c1"></span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Feb 27</span></p><p class="c2"><span class="c1">Finished up initial work on understanding influxd generate along with pkg/data/gen and how it melds random numbers into the spec which gets generated via the schema.toml file.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Feb 21</span></p><p class="c2"><span class="c1">Toml is the key to understanding schemas in influx, so we are going through a review of the toml spec.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Feb 18, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">Got the influxdb models package up and running standalone and sent in my first PR to make the models package independent of tsdb. &nbsp;Discussed with </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://influxcommunity.slack.com/archives/CH8RV8PK5/p1582066416080000?thread_ts%3D1582064001.068600%26cid%3DCH8RV8PK5&amp;sa=D&amp;source=editors&amp;ust=1614990639749000&amp;usg=AOvVaw3dzrY4cRhmSXszpFmp7v9y">Jonathan Sternberg on Slack today</a></span><span class="c1">...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Feb 13, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">So I got the xbrl xml ubnt file parsed into json and beyond via Javascript. &nbsp;I think now it might be easy to do in Rust as well, see my repo </span><span class="c13">parse-xbrl-test</span><span class="c1">&nbsp;for more details. &nbsp;I now believe that I will be both a better Rust and Go programmer because coming back to Go now I am better able to understand what is going on. &nbsp;Hit upon the influxdata/line-protocol github repo and realized how simple the Metric is and how they built a HUGE idea and company and product out of this very simple line-protocol Metric data structure.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Feb 11, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Back into influxdb possibly... &nbsp;Got it up and running on my machine. &nbsp;Might continue exploring time series data for ubnt and fundamental and technical mix signals.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Feb 10, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Deep dive into bayard for the first time. &nbsp;My initial hit is that I am very impressed. &nbsp;Start looking at how to write a javascript client so you can embed a search bar and talk to bayard in javascript instead of using rust and wasm ? &nbsp;The idea would be to use grpc.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Feb 3, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Get tantivy-cli up and running on 11.3 based on a better understanding of Iterators, maps, filters and collect.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Jan 27, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Finally after months of work I now am reading a file of hackernews lines in json that contain an ID and a TITLE and writing those to a tantivy index and then searching across that data. &nbsp;Getting the data into redis properly and pre and post processing that stuff took probably more work than it should have but when one is learning a new programming language everything takes longer. &nbsp;Hopefully I will stick around Rust for awhile.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Jan 05, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Breakthrough on understanding that the fastfield code is just one of the SegmentComponents and that each individual segment component has its own serializer, file format, and reader / writer which are independent of each other.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Jan 03, 2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">More work on the directory package in Tantivy including the general concept behind mmap...</span></p><p class="c0"><span class="c1"></span></p><p class="c16 title" id="h.mz3skcjdwxp6"><span class="c15 c7">2020</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c21 c7 c22">So I am only keeping part of 2019 to keep 2020 in context to what I was working on in 2019. &nbsp; I go back to my start of tantivy which goes back to Maria&#39;s birthday on Oct 22, 2019...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Mon Dec 23, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Understanding the term, terminfo and pointer into postings and positions along with the document store.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sun Dec 22, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">First day working on fst. &nbsp;I read some of the blog post by burntsushi and got some of the fst code up and running with the examples.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sat Dec 21 (winter solstice, hb is going to the party in OR)</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So the year is ending on a good note, and my rust skills are in pretty good shape. &nbsp;I am finally starting to feel a bit productive, after starting to code in Rust on Scott&#39;s bday this year, so its been over 5 months now.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Today I got the code working to rebuild a json document based on the keys in the tantivy schema. &nbsp;It involved using a Map from serde-json, crossbeam channels for the first time, HashSets. &nbsp;I am pretty confident I can take a few weeks off from coding while I am back home in NM and get right back into some time in mid January once I am back home in OR.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Wed Dec 18</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Up and running (again) with tantivy-cli. &nbsp;I got a new working example up and running, and pretty much understand how it works. &nbsp;Will outline the next steps in coming days. &nbsp;But for now I got the data coming from Hn and going into Redis, Sled, and Files which is where I wanted to get to. &nbsp;Now I am going to get up and running with easily getting the data into Tantivy.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Dec 17, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Moving on now to a new architecture with channels. &nbsp;So both IDs and Json Strings will go on channels moving forward.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Sunday Dec 15, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Starting to get sled working with the hacker news json data. &nbsp;First cut at sled up and running and finished.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Dec 10, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">The day of flying to Florida I got the data into redis in the repo redsled. &nbsp;I just took the code from yesterday and added the method to write the data that was already in a vector out to redis.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Dec 09, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">The day before going to Fl I got the lifetimes example working noted in last Friday&#39;s entry. &nbsp;This is kind of HUGE and the next step in learning Rust. &nbsp;As I look over the Rust Book and what I still don&#39;t know, this was something I definitely needed to get down. &nbsp;So now I can take the rest of the day off :) &nbsp;See you in Florida. &nbsp;Its been a very productive time in Rust land here in Pittsburgh. &nbsp;I pretty much worked almost every single day and didn&#39;t take any days off while I was home. &nbsp;So until I get back to Oregon in mid January you can rest assured knowing you aren&#39;t a slacker when it comes to work :)</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Dec 06, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So I have been coding in Rust pretty much every day since arriving here in Pittsburgh and from the beginning on July 10. &nbsp;Today is the first time I ran into the borrow checker, lifetimes, and ownership, so this is pretty cool.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Here is the problem. &nbsp;I am reading data out of a file and passing that data into a Vector which then gets passed along somewhere else. &nbsp;The line iterator of the file owns the data and I want to be able to have a lifetime stating that the data lives on after the line iterator goes out of scope but the vector still can have a reference to the data.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">The fact that I am able to create a problem that uses these concepts is pretty cool. &nbsp;This may take a while to wrap my head around so stay tuned.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Dec 05</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Booked a ticket today to fly to ABQ on Dec 25 for $189. &nbsp;Believe it or not but this one line of code took me a couple of hours to figure out. &nbsp;Where keys is a vector, and I was trying to assign it to a variable via let x = but all it wanted was Vector on its own line calling the sort method. &nbsp;I was sorting a Vector of hash keys which are the hackernews ids for stories only.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">&nbsp;</span><span class="c6">&nbsp; &nbsp;let mut keys = get_hashmap_keys(&quot;hn-story-19&quot;.to_string()).unwrap();</span></p><p class="c2"><span class="c6">&nbsp; &nbsp; keys.sort();</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Dec 02</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">So the null checks and everything else is running, now moving on to storing the data using both sled and probably redis too.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Nov 30</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Lunch at Cafe 33 Taiwanese, yummy.</span></p><p class="c2"><span class="c1">Got null checks working in the repo hn-api-examples</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Nov 29, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">hn-api-examples is up and running and I am parsing tens of thousands of hn json&#39;s with no errors. &nbsp;only thing left to do is handle the case where there is a null.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">make sure you understand this line of code:</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c21">Item::Comment(comment) =&gt; Some(&amp;comment.by.</span><span class="c11">as_ref().unwrap()</span><span class="c6">),</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Monday Nov 18</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Up and running and the serde deserialization of a Hackernews json object is up and running.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Nov 16</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Working on serde serial, deserial of hackernews in the context of spaceapi-rs. &nbsp;It is starting to work...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Thursday Nov 14</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Note when I started coding in Rust we were at 1.36.0 and now today I installed 1.39.0</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">So the past couple of days in Pittsburgh have been trying and a bit brutal getting my async, tokio code working, but I am there with this rust-hackernews </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://github.com/stormasm/rust-hackernews/blob/master/hn00/examples/ex02.rs&amp;sa=D&amp;source=editors&amp;ust=1614990639763000&amp;usg=AOvVaw1JDDU4KLEGUj-miqOLGLkK">code</a></span><span class="c4">. &nbsp;It iterates over a set of hackernews favorite ids, gets the JSON body from </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://hacker-news.firebaseio.com/v0/item/8863.json&amp;sa=D&amp;source=editors&amp;ust=1614990639764000&amp;usg=AOvVaw00I3pkKZA2yt6q_Md48-ax">here</a></span><span class="c4">, and writes the data to a redis hashmap. &nbsp;Pretty cool, and I believe it helped today to install the latest stable version of rust 1.39.0 which is the first version to support </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://blog.rust-lang.org/2019/11/07/Async-await-stable.html&amp;sa=D&amp;source=editors&amp;ust=1614990639764000&amp;usg=AOvVaw1rwgsv3YKpzNqCC4LhCpTk">async-await</a></span><span class="c4">&nbsp;and here is the </span><span class="c9 c4"><a class="c3" href="https://www.google.com/url?q=https://news.ycombinator.com/item?id%3D21473259&amp;sa=D&amp;source=editors&amp;ust=1614990639764000&amp;usg=AOvVaw0AVVMzJylJYkRh8xBONKpB">hackernews post</a></span><span class="c1">&nbsp;which got 1100 points, wow ! &nbsp;Initially I tried to tackle it using the hyper client code but then quickly realized that reqwest which was a much easier route to take.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday Nov 9</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">I am in pretty good shape with the tantivy schema mod, and today I got a good handle on NamedFieldDocument which I learned is mainly used to help with document conversion to json.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday Nov 05, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">In the morning before flying out to Pittsburgh. &nbsp;More work on tantivy, now looking at the Document and the schema crate in tantivy in relationship to the spaceapi-server concept but using this api to store tantivy documents, elastic-search documents, and possibly the concept of writing a tutorial on how to port data from elastic to tantivy using vector ?</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">also, with redis in mind fully understand how to use the RedisPool. &nbsp;I will basically get this for free as I unwind the spaceapi-server. &nbsp;For a second opinion on redis-pool take a look at sidekiq as well...</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Saturday October 26, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c4">This week I started working on search in rust, more specifically, </span><span class="c13">tantivy and sonic</span><span class="c1">. &nbsp;I am not sure how I got here, but basically I wanted to store all of my hackernews favorite json files on redis or sled and then be able to search across them when it hit smack in the middle of the face that why not use a search engine library, and then I found tantivy and sonic. &nbsp;Life continues to twist and turn and its very strange how you discover the rocks and then eventually you turn them over.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Tuesday October 22, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Maria&#39;s birthday and Day 1 of tantivy.</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Friday Sep 27, 2019</span></p><p class="c0"><span class="c1"></span></p><p class="c2"><span class="c1">Finally after many months of trying to understand Rust I am starting to code. &nbsp;The past 2 days have been working on reading the data back from Redis that maman writes to it... &nbsp;So I am finally am able to get at the data, and in doing so, am actually writing some Rust code.</span></p><p class="c0 c8"><span class="c7 c17 c18"></span></p></body></html>